"""
Jarvis AI Assistant Integration Module

This module provides the integration point between the Jarvis AI Assistant
and the user interface. It defines the JarvisAI class that handles natural
language processing and response generation.

This is a template implementation that should be replaced with your actual
Jarvis AI implementation. The template provides basic functionality to demonstrate
the integration pattern, but lacks advanced AI capabilities.

Integration Requirements:
1. Maintain the JarvisAI class with the same interface
2. Implement the process_query method that takes a string query and returns a string response
3. Handle initialization and model loading in the __init__ method

Author: Nada Mohamed
License: MIT
"""

import os  # Used for file path operations
import logging  # Used for application logging
from typing import Dict, Optional

# Import model handlers
from server.jarvis.models import MODEL_HANDLERS, ModelHandler

# Configure logger for this module
# This logger will be used to track the assistant's operations
logger = logging.getLogger('jarvis_assistant')

class JarvisAI:
    """
    Jarvis AI Assistant class.

    This class serves as the main interface for the Jarvis AI Assistant.
    It handles:
    1. Initialization and loading of AI models
    2. Processing user queries
    3. Generating appropriate responses

    This is a sample implementation that should be replaced with your actual
    Jarvis AI implementation. When implementing your own version, maintain
    the same interface to ensure compatibility with the UI.
    """

    def __init__(self, model_path=None):
        """
        Initialize the Jarvis AI Assistant.

        This method:
        1. Sets up the model path
        2. Loads any necessary AI models
        3. Initializes the assistant's state

        Args:
            model_path (str, optional): Path to the model files. If None, a default
                                        path will be used based on the application's
                                        directory structure. Defaults to None.
        """
        # Determine the model path - either use the provided path or calculate the default
        # The default path is: <app_root>/data/models
        self.model_path = model_path or os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))),
            'data',
            'models'
        )
        logger.info(f"Initializing Jarvis AI with model path: {self.model_path}")

        # TODO: Initialize your actual Jarvis AI model here
        # This is where you would load your language model, embeddings, or other AI components
        # Example:
        # from transformers import AutoModelForCausalLM, AutoTokenizer
        # self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
        # self.model = AutoModelForCausalLM.from_pretrained(self.model_path)
        self.model = None

        # Initialize any other components or state variables needed by the assistant
        self.conversation_history = []

        # Initialize model handlers with the same model path
        self.model_handlers: Dict[str, ModelHandler] = {}
        for model_type, handler in MODEL_HANDLERS.items():
            handler.model_path = self.model_path
            self.model_handlers[model_type] = handler

        # Current active model type (default to text generation)
        self.current_model_type = "textGeneration"

        logger.info("Jarvis AI initialized")

    def _get_datetime_info(self):
        """
        Helper method to get current date and time information.

        Returns:
            tuple: (current_time_str, current_date_str) formatted strings
        """
        import datetime
        now = datetime.datetime.now()
        current_time = now.strftime("%I:%M %p")
        current_date = now.strftime("%A, %B %d, %Y")
        return current_time, current_date

    def process_query(self, query, model_type=None):
        """
        Process a user query and return an appropriate response.

        This method:
        1. Analyzes the user's query
        2. Determines the appropriate model to use
        3. Generates and returns the response text

        Args:
            query (str): The user's natural language query text
            model_type (str, optional): The type of model to use. If None, the current model type will be used.

        Returns:
            str: The AI assistant's response text
        """
        # Log the incoming query for debugging and monitoring
        logger.info(f"Processing query: {query}")

        # Check for model type in the query
        if model_type:
            # If a specific model type is requested, use it
            self.current_model_type = model_type
            logger.info(f"Using specified model type: {model_type}")
        else:
            # Check if the query contains keywords that indicate a specific model type
            query_lower = query.lower()

            # Simple keyword detection for model type
            if any(keyword in query_lower for keyword in ["code", "program", "function", "class"]):
                self.current_model_type = "codeGeneration"
            elif any(keyword in query_lower for keyword in ["story", "tale", "narrative"]):
                self.current_model_type = "storyGeneration"
            elif any(keyword in query_lower for keyword in ["analyze", "sentiment", "extract", "classify"]):
                self.current_model_type = "nlp"
            elif "transcribe" in query_lower:
                self.current_model_type = "speechToText"
            # Default to text generation if no specific keywords are found

            logger.info(f"Detected model type from query: {self.current_model_type}")

        # Get the appropriate model handler
        if self.current_model_type in self.model_handlers:
            handler = self.model_handlers[self.current_model_type]
            logger.info(f"Using model handler: {self.current_model_type}")

            # Process the query with the selected model handler
            response = handler.process_query(query)
            return response
        else:
            # Fallback to basic responses if the model type is not recognized
            logger.warning(f"Unknown model type: {self.current_model_type}, using fallback responses")

            # Store lowercase version of query for easier matching
            query_lower = query.lower()

            # Basic pattern matching for common queries
            # Greeting detection
            if "hello" in query_lower or "hi" in query_lower:
                return "Hello! I'm Jarvis, your AI assistant. How can I help you today?"

            # Weather query detection
            if "weather" in query_lower:
                return "I'm sorry, I don't have access to real-time weather data in this offline mode."

            # Time query detection
            if "time" in query_lower:
                current_time, _ = self._get_datetime_info()
                return f"The current time is {current_time}."

            # Date query detection
            if "date" in query_lower:
                _, current_date = self._get_datetime_info()
                return f"Today is {current_date}."

            # Gratitude detection
            if "thank" in query_lower:
                return "You're welcome! Is there anything else I can help you with?"

            # Farewell detection
            if "bye" in query_lower or "goodbye" in query_lower:
                return "Goodbye! Feel free to chat with me anytime."

            # Check if this is a command query
            from commands.run import execute_command
            
            # Try to execute as a command
            try:
                command_result = execute_command(query_lower)
                if command_result.get('success'):
                    return command_result.get('message', 'Command executed successfully')
                elif command_result.get('error'):
                    return f"Error executing command: {command_result['error']}"
            except Exception as e:
                logger.error(f"Error executing command: {e}")
            
            # Default response for unrecognized queries
            return f"I've received your query: '{query}'. I'm not sure how to process this with the current configuration."

    def set_model_type(self, model_type):
        """
        Set the current model type to use for processing queries.

        Args:
            model_type (str): The type of model to use

        Returns:
            bool: True if the model type was set successfully, False otherwise
        """
        if model_type in self.model_handlers:
            self.current_model_type = model_type
            logger.info(f"Set current model type to: {model_type}")
            return True
        else:
            logger.warning(f"Unknown model type: {model_type}")
            return False
